{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de94d03d",
   "metadata": {},
   "source": [
    "# Import importlib para la carga y reinicio de los import del modulo data_processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a69ce50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b83be55",
   "metadata": {},
   "source": [
    "# Importar normalize.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0154b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'data_processing.normalize' from '/home/angel/Proyects/python/laboratorios/lab1_programacion_cientifica/data_processing/normalize.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import data_processing.normalize as norm\n",
    "importlib.reload(norm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874e4b49",
   "metadata": {},
   "source": [
    "# Importar stop_words.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "969fdd5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'data_processing.stop_words' from '/home/angel/Proyects/python/laboratorios/lab1_programacion_cientifica/data_processing/stop_words.py'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import data_processing.stop_words as stop\n",
    "importlib.reload(stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def04956",
   "metadata": {},
   "source": [
    "# Importar TF.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "97c590ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'data_processing.TF' from '/home/angel/Proyects/python/laboratorios/lab1_programacion_cientifica/data_processing/TF.py'>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import data_processing.TF as tf\n",
    "importlib.reload(tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89df886",
   "metadata": {},
   "source": [
    "# Importar IDF.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f991387",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'data_processing.IDF' from '/home/angel/Proyects/python/laboratorios/lab1_programacion_cientifica/data_processing/IDF.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import data_processing.IDF as idf\n",
    "importlib.reload(idf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2e86dc",
   "metadata": {},
   "source": [
    "# Lectura de Documentos de una direccion, devuelve una lista de documentos, como tal la lista representa un corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b3e31387",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_doc_dir(dir):\n",
    "    list_documents = []\n",
    "    position = 1\n",
    "    dir = dir.rstrip('/')\n",
    "    while True:\n",
    "        try:\n",
    "            with open(f'{dir}/doc_{position}.txt','r', encoding='UTF-8') as arch:\n",
    "                list_documents.append(arch.read())\n",
    "                position+=1\n",
    "        except FileNotFoundError:\n",
    "            break\n",
    "        except:\n",
    "            print(f'erro al leer {dir}/doc_{position}.txt: {e}')\n",
    "    if not list_documents:\n",
    "        print('Direcci칩n inv치lida o no tiene documentos')\n",
    "\n",
    "    return list_documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77dc4187",
   "metadata": {},
   "source": [
    "# Aplicando Normalizaci칩n y Stop-Words, al corpus (formato de lista de documentos) dado, retorna una lista de docs y cada doc es una lista de palabras def norm_and_stop_words(corpus, language): language == 'en' para ingles y language == 'es' espa침ol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "53959cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_and_stop_words(corpus, language):\n",
    "    val = False\n",
    "    if language == 'en':\n",
    "        val = True\n",
    "        corpus = [norm.normalize(doc,language) for doc in corpus]\n",
    "        corpus = [stop.delete_stop_words_en(doc.split()) for doc in corpus]\n",
    "    elif language == 'es':\n",
    "        val = True\n",
    "        corpus = [norm.normalize(doc,language) for doc in corpus]\n",
    "        corpus = [stop.delete_stop_words_es(doc.split()) for doc in corpus]\n",
    "    \n",
    "    if not val:\n",
    "        print('idioma mal escrito o no aceptado (en/es) solamente')\n",
    "    \n",
    "    return corpus"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
